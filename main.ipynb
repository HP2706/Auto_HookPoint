{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from __future__ import annotations\n",
    "from inspect import isclass\n",
    "from torch import nn\n",
    "from transformer_lens.hook_points import HookPoint, HookedRootModule\n",
    "from typing import List, Optional, TypeVar, Type, Union, cast, overload\n",
    "from utils import iterate_module\n",
    "from abc import ABC, abstractmethod\n",
    "import torch\n",
    "from functools import partial\n",
    "from fastcore.basics import *\n",
    "from fastcore.foundation import *\n",
    "from torch import nn\n",
    "from transformer_lens.hook_points import HookPoint\n",
    "from typing import TypeVar, Generic, Union, Type, Any, Callable, get_type_hints, ParamSpec, Protocol\n",
    "from inspect import isclass, signature\n",
    "import functools\n",
    "from fastapi import FastAPI\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\" \n",
    "class AutoHookedRootModule(HookedRootModule):\n",
    "    '''\n",
    "    This class automatically builds hooks for all modules that are not hooks.\n",
    "    NOTE this does not mean all edges in the graph are hooked only that the outputs of the modules are hooked.\n",
    "    for instance torch.softmax(x) is not hooked but self.softmax(x) would be\n",
    "    ''' \"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "class ModelTest(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.bla = nn.ModuleList([nn.Linear(10, 10)])\n",
    "        self.lala = nn.Linear(10, 10)\n",
    "\n",
    "    def forward(self, x):\n",
    "        if isinstance(self, AutoHookedRootModule):\n",
    "            print(f'{self.__class__.__name__}.mod_dict', self.mod_dict)\n",
    "            print(self.bla[0], self.bla[0].hook_dict)\n",
    "        x = self.bla[0].forward(x)\n",
    "        x = self.lala.forward(x)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "T = TypeVar('T', bound=nn.Module)\n",
    "P = ParamSpec('P')\n",
    "_T = TypeVar(\"_T\", bound=Callable)\n",
    "\n",
    "\n",
    "def same_definition_as_in(t: _T) -> Callable[[Callable], _T]:\n",
    "    def decorator(f: Callable) -> _T:\n",
    "        return f  # type: ignore\n",
    "\n",
    "    return decorator\n",
    "\n",
    "class MyFastAPI(FastAPI):\n",
    "    @same_definition_as_in(FastAPI.__init__)\n",
    "    def __init__(self, *args, **kwargs):\n",
    "        super().__init__(*args, **kwargs) \n",
    "\n",
    "    @same_definition_as_in(FastAPI.get)\n",
    "    def get(self, *args, **kwargs):\n",
    "        print('get')\n",
    "        return super().get(*args, **kwargs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "T = TypeVar('T', bound=nn.Module)\n",
    "P = ParamSpec('P')\n",
    "R = TypeVar('R')\n",
    "\n",
    "class WrappedInstance(HookedRootModule, Generic[T]):\n",
    "    def __init__(self, module: T):\n",
    "        super().__init__()\n",
    "        self._module = module\n",
    "        self.hook_point = HookPoint()\n",
    "        self._create_forward()\n",
    "        self.setup()\n",
    "\n",
    "    def unwrap(self) -> T: ...\n",
    "\n",
    "    def _create_forward(self):\n",
    "        original_forward = self._module.forward\n",
    "        original_type_hints = get_type_hints(original_forward)\n",
    "\n",
    "        @functools.wraps(original_forward)\n",
    "        def new_forward(*args: Any, **kwargs: Any) -> Any:\n",
    "            # Remove 'self' from args if it's present\n",
    "            if args and isinstance(args[0], WrappedInstance):\n",
    "                args = args[1:]\n",
    "            return self.hook_point(original_forward(*args, **kwargs))\n",
    "\n",
    "        new_forward.__annotations__ = original_type_hints\n",
    "        setattr(self.__class__, 'forward', new_forward)\n",
    "\n",
    "class WrappedClass(Generic[T]):\n",
    "    def __init__(self, module_class: Type[T]) -> T: # type: ignore\n",
    "        self.module_class = module_class\n",
    "\n",
    "    def __call__(self, *args: Any, **kwargs: Any) -> WrappedInstance[T]:\n",
    "        instance = self.module_class(*args, **kwargs)\n",
    "        return auto_wrap(instance)\n",
    "\n",
    "    def __getattr__(self, name: str) -> Any:\n",
    "        return getattr(self.module_class, name)\n",
    "\n",
    "    def unwrap(self) -> Type[T]:\n",
    "        return self.module_class\n",
    "\n",
    "@overload\n",
    "def auto_wrap(module_or_class: Type[T]) -> WrappedClass[T]: ...\n",
    "\n",
    "@overload\n",
    "def auto_wrap(module_or_class: T) -> WrappedInstance[T]: ...\n",
    "\n",
    "def auto_wrap(module_or_class: Union[T, Type[T]]) -> Union[WrappedInstance[T], WrappedClass[T]]:\n",
    "    '''\n",
    "    This function wraps either a module instance or a module class and returns a type that\n",
    "    preserves the original module's interface plus an additional unwrap method.\n",
    "    '''\n",
    "    if isclass(module_or_class):\n",
    "        return WrappedClass(module_or_class)\n",
    "    else:\n",
    "        wrapped = WrappedInstance(module_or_class)\n",
    "        #NOTE we set the unwrap method to just return module_or_class\n",
    "        wrapped.unwrap = lambda: module_or_class # type: ignore\n",
    "        return cast(WrappedInstance[T], wrapped)\n",
    "\n",
    "WrappedLinear1 = auto_wrap(nn.Linear)(1,1)\n",
    "WrappedLinear2 = auto_wrap(nn.Linear(10,1))\n",
    "\n",
    "#WrappedLinear1.mod_dict\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "metadata": {},
   "outputs": [],
   "source": [
    "#BASIC TESTS\n",
    "WrappedLinear1 = auto_wrap(nn.Linear)\n",
    "WrappedLinear2 = auto_wrap(nn.Linear(10,1))\n",
    "\n",
    "def test_types():\n",
    "    WrappedLinear1Instance = WrappedLinear1(1, 1)\n",
    "    assert type(WrappedLinear1Instance) == type(WrappedLinear2), f\"{type(WrappedLinear1Instance)} != {type(WrappedLinear2)}\"\n",
    "    assert type(WrappedLinear1Instance.unwrap()) == type(WrappedLinear2.unwrap()) , f\"{type(WrappedLinear1Instance.unwrap())} != {type(WrappedLinear2.unwrap())}\"\n",
    "    assert WrappedLinear1.unwrap() == type(WrappedLinear2.unwrap()), f\"{WrappedLinear1.unwrap()} != {type(WrappedLinear2.unwrap())}\"\n",
    "\n",
    "def test_type_hints():\n",
    "    linear_type_hints = get_type_hints(nn.Linear(10, 20).forward)\n",
    "    wrapped_linear_instcane_type_hints = get_type_hints(WrappedLinear2.forward)\n",
    "    wrapped_linear_class_type_hints = get_type_hints(WrappedLinear1.forward)\n",
    "    assert linear_type_hints == wrapped_linear_instcane_type_hints, f\"{linear_type_hints} != {wrapped_linear_instcane_type_hints}\"\n",
    "    assert linear_type_hints == wrapped_linear_class_type_hints, f\"{linear_type_hints} != {wrapped_linear_class_type_hints}\"\n",
    "\n",
    "test_types()\n",
    "test_type_hints()\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ml",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
